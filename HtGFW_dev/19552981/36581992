19552981
article
36581992
https://zhuanlan.zhihu.com/p/36581992
Yiqin Fu
数据清洗的经验与教训 Data Cleaning（二）

上一次写教训总结已经是一年前了。最近又浪费了不少时间，所以把原因写出来，可能有的错误比较初级。我看的都是社会科学类数据（最多几百万行），使用 R 和 Python。经验不一定适用于其他场景、其他软件。使用各种包的注意事项包的加载有先后顺序。如果两个包有重名的命令，最后加载的那个会覆盖前面的。所以推荐最后加载平时最常用、最熟悉的包R 里面可以用包的名字::命令这个格式只加载某个包的某个命令。这么做的好处是这个包的其他命令不会加载，也就不可能覆盖你常用的命令如果现在的包能用，哪怕有强迫症（我）也不要随意更新包，否则之前的代码可能会用不了使用刚开发或刚更新的包如果出错，可能不一定是你的问题，而是包的作者写错了。这时候可以：手写基础命令，计算一下是不是包的结果错了去包的 Github Issues 页面看看，说不定有人已经指出了问题真有时间可以去看包的底层代码如果包确实有错，一定记得花点时间告诉包的作者。有的人不仅会回复、修正，还会特别感谢你 =）有合作者的时候尽量让比较会命名的一方来命名新变量。如果有人（我）想了半天也只能想出df_subset这种名字，千万不要让他命名新变量 统一说好命名新变量、新文件用什么格式，例如 vote.share，vote_share，vote-share ，voteShare。不统一的话会非常容易出错保持随手更新项目文档的习惯，否则时间长了互相都搞不清楚对方做了什么上传 Github 的时候加入 .gitignore 文件，让它忽略文件修改历史。不加的话，合作者会知道你（我）画一张图画了二十次复杂项目把代码按照“加载”、“预处理”、“处理方法1”、“处理方法2”等步骤分开放在不同文件里，这样如果以后需要用新方法处理数据，只需要调用“加载”和“预处理”文件再处理即可。初写代码的时候如果偷懒把所有步骤放在一个文件里，最后要换方法处理数据会非常麻烦读写数据把数据存 .Rdata格式，大小会比.csv和.txt 小很多同样的内容，.csv不一定比.xlsx小 手动录入数据进 Excel，我的电脑（很老的 Mac）大概在 3,000 行就开始卡。Mac 的 Numbers 快很多，最新版也加入了根据自定义分隔符或固定间距分列清洗数据英文世界的常见词转换通常都有现成的包，不用手写（例如文字日期到数字日期，国名、州名到缩写）中文和日文有的字看起来一样，但匹配的时候会匹配不了现在用 R 的人越来越多，以前我非常想要的两个功能都有人开发了包（一个是patchwork，可以把很多ggplot图放在一起；一个是summarytables，可以把描述性统计数据批量做成图或者输出成表格）。从 R 输出到各种格式的工具也越来越多，连 LaTex 都有，希望可以赶紧用上这些包，以后 LaTex 就不需要用一次搜索一次了。本系列其他文章：数据清洗的经验与教训 Data Cleaning（一）从哪里可以免费、低成本获得靠谱的数据？